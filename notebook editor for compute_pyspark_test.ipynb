{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-py36",
      "display_name": "Python (env py36)",
      "language": "python"
    },
    "associatedRecipe": "compute_pyspark_test",
    "creator": "admin",
    "createdOn": 1672319987786,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nfrom dataiku import spark as dkuspark\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\n\nsc \u003d SparkContext.getOrCreate()\nsqlContext \u003d SQLContext(sc)\n\n# Read recipe inputs\nInline_dataset_prepared \u003d dataiku.Dataset(\"Inline_dataset_prepared\")\nInline_dataset_prepared_df \u003d dkuspark.get_dataframe(sqlContext, Inline_dataset_prepared)\n\n# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a SparkSQL dataframe\npyspark_test_df \u003d Inline_dataset_prepared_df # For this sample code, simply copy input to output\n\n# Write recipe outputs\npyspark_test \u003d dataiku.Dataset(\"pyspark_test\")\ndkuspark.write_with_schema(pyspark_test, pyspark_test_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/centos/dataiku-dss-11.2.0/spark-standalone-home/python/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  FutureWarning,\n/home/centos/dataiku-dss-11.2.0/spark-standalone-home/python/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n",
          "name": "stderr"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}